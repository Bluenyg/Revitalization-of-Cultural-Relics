import os

# --- 0. åŸºç¡€é…ç½®ä¸ç¯å¢ƒè®¾ç½® ---
# å¿…é¡»åœ¨å¯¼å…¥ä»»ä½• langchain/chromadb åº“ä¹‹å‰è®¾ç½®ï¼Œé˜²æ­¢ Telemetry æŠ¥é”™
os.environ["ANONYMIZED_TELEMETRY"] = "False"
os.environ["ALLOW_RESET"] = "True"

import streamlit as st
import json
import glob
import re  # å¼•å…¥æ­£åˆ™åº“ç”¨äºè§£æ <think> æ ‡ç­¾
from datetime import datetime

from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="å›½å®AIæ´»åŒ–å·¥ä½œå°",
    page_icon="ğŸ´",
    layout="wide"
)

# å®šä¹‰è·¯å¾„
CHROMA_DB_DIR = "./chroma_db"
HISTORY_DIR = "./chat_history"
OLLAMA_URL = "http://localhost:11434"

# ç¡®ä¿å†å²è®°å½•ç›®å½•å­˜åœ¨
if not os.path.exists(HISTORY_DIR):
    os.makedirs(HISTORY_DIR)


# --- 1. è¾…åŠ©å‡½æ•°ï¼šè§£æä¸æ¸²æŸ“æ¶ˆæ¯ ---

def parse_and_render_message(text):
    """
    æ ¸å¿ƒæ¸²æŸ“å‡½æ•°ï¼š
    æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å« <think> æ ‡ç­¾ã€‚
    å¦‚æœæœ‰ï¼Œå°†æ€è€ƒè¿‡ç¨‹æ”¾å…¥ st.expander æŠ˜å æ¡†ï¼Œ
    å°†æ­£å¼å›ç­”æ”¾å…¥ markdownã€‚
    """
    # ä½¿ç”¨éè´ªå©ªåŒ¹é…æå– <think> å†…å®¹
    pattern = r"<think>(.*?)</think>(.*)"
    match = re.search(pattern, text, re.DOTALL)

    if match:
        thought_content = match.group(1).strip()
        answer_content = match.group(2).strip()

        # 1. æ¸²æŸ“æ€è€ƒè¿‡ç¨‹ï¼ˆé»˜è®¤æŠ˜å ï¼‰
        if thought_content:
            with st.expander("ğŸ’­ æ¨¡å‹æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)", expanded=False):
                st.markdown(thought_content)

        # 2. æ¸²æŸ“æ­£å¼å›ç­”
        if answer_content:
            st.markdown(answer_content)
        else:
            st.info("æ¨¡å‹ä»…è¾“å‡ºäº†æ€è€ƒè¿‡ç¨‹ï¼Œæœªç”Ÿæˆæœ€ç»ˆå›ç­”ã€‚")
    else:
        # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œç›´æ¥æ˜¾ç¤ºå…¨æ–‡
        clean_text = text.replace("<think>", "**[å¼€å§‹æ€è€ƒ]**\n").replace("</think>", "\n**[æ€è€ƒç»“æŸ]**\n")
        st.markdown(clean_text)


# --- 2. å†å²è®°å½•ç®¡ç† ---

def save_chat_history(chat_id, messages):
    """å°†å½“å‰å¯¹è¯ä¿å­˜åˆ° JSON æ–‡ä»¶"""
    file_path = os.path.join(HISTORY_DIR, f"{chat_id}.json")
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(messages, f, ensure_ascii=False, indent=4)


def load_chat_history(chat_id):
    """è¯»å–å†å²å¯¹è¯"""
    file_path = os.path.join(HISTORY_DIR, f"{chat_id}.json")
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


def get_chat_history_list():
    """è·å–æ‰€æœ‰å†å²è®°å½•æ–‡ä»¶ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´æ’åº"""
    files = glob.glob(os.path.join(HISTORY_DIR, "*.json"))
    files.sort(key=os.path.getmtime, reverse=True)
    return files


def get_chat_title(messages):
    """æ ¹æ®ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ç”Ÿæˆæ ‡é¢˜"""
    for msg in messages:
        if msg["role"] == "user":
            content = msg["content"]
            # å¦‚æœæ ‡é¢˜è¿‡é•¿ï¼Œæˆªå–å‰12ä¸ªå­—ç¬¦
            return content[:12] + "..." if len(content) > 12 else content
    return "æ–°å¯¹è¯"


def init_new_chat():
    """é‡ç½®ä¸ºæ–°å¯¹è¯çŠ¶æ€"""
    new_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    st.session_state.current_chat_id = new_id
    st.session_state.messages = [
        {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„å›½å®æ´»åŒ–åŠ©ç†ã€‚å…³äºâ€œèˆé©¬è¡”æ¯ä»¿çš®å›Šå¼é“¶å£¶â€ï¼Œä½ æœ‰ä»€ä¹ˆå¤§èƒ†çš„åˆ›ä½œæƒ³æ³•ï¼Ÿ"}
    ]


# --- 3. åˆå§‹åŒ– Session State ---

if "current_chat_id" not in st.session_state:
    init_new_chat()


# --- 4. åŠ è½½ RAG æ¨¡å‹ (ç¼“å­˜) ---

@st.cache_resource
def load_rag_chain():
    # Embedding
    embeddings = OllamaEmbeddings(base_url=OLLAMA_URL, model="nomic-embed-text")

    # Vector DB
    if not os.path.exists(CHROMA_DB_DIR):
        st.error("âŒ æœªæ‰¾åˆ°å‘é‡æ•°æ®åº“ã€‚è¯·å…ˆåœ¨ç»ˆç«¯è¿è¡Œ `python3 ingest.py` ç”ŸæˆçŸ¥è¯†åº“ï¼")
        st.stop()

    vector_store = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings)

    # æ™ºèƒ½è°ƒæ•´ k å€¼
    try:
        collection_count = vector_store._collection.count()
        k_val = min(4, collection_count)
        if k_val == 0: k_val = 1
    except:
        k_val = 4

    retriever = vector_store.as_retriever(search_kwargs={"k": k_val})

    # LLM
    llm = ChatOllama(base_url=OLLAMA_URL, model="qwen3:14b", temperature=0.3)
    return retriever, llm


try:
    retriever, llm = load_rag_chain()
except Exception as e:
    st.error(f"æ— æ³•è¿æ¥æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ Ollama æœåŠ¡ã€‚é”™è¯¯: {e}")
    st.stop()

# --- 5. ä¾§è¾¹æ  UI ---

with st.sidebar:
    st.image("https://img.icons8.com/color/96/museum.png", width=80)
    st.title("ğŸ´ å›½å®ç”»é‡ç‚¹")

    st.subheader("ğŸ—‚ï¸ å¯¹è¯ç®¡ç†")

    if st.button("â• æ–°å»ºå¯¹è¯", use_container_width=True):
        init_new_chat()
        st.rerun()

    with st.expander("ğŸ“œ å†å²è®°å½•", expanded=True):
        files = get_chat_history_list()

        if not files:
            st.caption("æš‚æ— å†å²è®°å½•")

        for file_path in files:
            file_name = os.path.basename(file_path)
            chat_id = file_name.replace(".json", "")

            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    msgs = json.load(f)
                title = get_chat_title(msgs)
                # æ ¼å¼åŒ–ä¸€ä¸‹æ—¥æœŸæ˜¾ç¤º
                date_str = f"{chat_id[4:6]}/{chat_id[6:8]} {chat_id[9:11]}:{chat_id[11:13]}"
            except:
                title = "æœªçŸ¥å¯¹è¯"
                date_str = chat_id

            # --- å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨åˆ—å¸ƒå±€ [åŠ è½½ 85% | åˆ é™¤ 15%] ---
            col1, col2 = st.columns([0.85, 0.15])

            with col1:
                # é€‰ä¸­çŠ¶æ€é«˜äº®é€»è¾‘ï¼ˆå¯é€‰ï¼Œé€šè¿‡ emoji åŒºåˆ†ï¼‰
                is_current = (st.session_state.current_chat_id == chat_id)
                label_prefix = "ğŸ“‚ " if is_current else ""
                display_label = f"{label_prefix}{title}\nRunning at {date_str}"

                if st.button(display_label, key=f"load_{chat_id}", use_container_width=True):
                    st.session_state.current_chat_id = chat_id
                    st.session_state.messages = msgs
                    st.rerun()

            with col2:
                # åˆ é™¤æŒ‰é’®
                if st.button("ğŸ—‘", key=f"del_{chat_id}", help="åˆ é™¤æ­¤å¯¹è¯"):
                    try:
                        os.remove(file_path)
                        # å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰æ­£åœ¨çœ‹çš„å¯¹è¯ï¼Œé‡ç½®ä¸ºæ–°å¯¹è¯
                        if st.session_state.current_chat_id == chat_id:
                            init_new_chat()
                        st.success("å·²åˆ é™¤")
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆ é™¤å¤±è´¥")

    st.divider()

    role = st.selectbox(
        "ğŸ­ é€‰æ‹© AI åŠ©ç†è§’è‰²",
        ("ä¸“å®¶å­¦è€… (ä¸¥è°¨è€ƒæ®)", "äº¤äº’è®¾è®¡å¸ˆ (ä½“éªŒåˆ›æ–°)", "ç¬¦å·å­¦è€… (æ–‡åŒ–éšå–»)", "ç­–å±•äºº (å™äº‹ä¼ æ’­)")
    )

    role_definitions = {
        "ä¸“å®¶å­¦è€… (ä¸¥è°¨è€ƒæ®)": "ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å†å²å­¦å®¶ã€‚ä½ çš„é‡ç‚¹æ˜¯è€ƒè¯å²å®ã€‚å¦‚æœç”¨æˆ·çš„åˆ›æ„ä¸ç¬¦åˆå”ä»£å†å²æˆ–æ–‡ç‰©äº‹å®ï¼Œè¯·æŒ‡å‡ºå¹¶æä¾›ä¾æ®ã€‚",
        "äº¤äº’è®¾è®¡å¸ˆ (ä½“éªŒåˆ›æ–°)": "ä½ æ˜¯ä¸€ä½å‰å«çš„äº¤äº’è®¾è®¡å¸ˆã€‚è¯·è¯„ä¼°ç”¨æˆ·çš„åˆ›æ„æ˜¯å¦å…·æœ‰äº’åŠ¨æ€§ï¼ˆå¦‚é‡åŠ›æ„Ÿåº”ã€æ‰‹åŠ¿ï¼‰ï¼Œå¹¶ç»™å‡ºä¼˜åŒ–å»ºè®®ã€‚",
        "ç¬¦å·å­¦è€… (æ–‡åŒ–éšå–»)": "ä½ æ˜¯ä¸€ä½ç¬¦å·å­¦ä¸“å®¶ã€‚è¯·è§£è¯»æ–‡ç‰©èƒŒåçš„æ–‡åŒ–éšå–»ï¼ˆå¦‚'èƒ¡æ±‰èåˆ'ï¼‰ï¼Œå¸®åŠ©ç”¨æˆ·æ·±åŒ–ä½œå“å†…æ¶µã€‚",
        "ç­–å±•äºº (å™äº‹ä¼ æ’­)": "ä½ æ˜¯ä¸€ä½æ–°åª’ä½“ç­–å±•äººã€‚è¯·ä»æŠ–éŸ³ä¼ æ’­çš„è§’åº¦ï¼ˆå®Œæ’­ç‡ã€è¯é¢˜æ€§ï¼‰è¯„ä¼°ç”¨æˆ·çš„æ–¹æ¡ˆã€‚"
    }
    st.info(f"**å½“å‰è®¾å®šï¼š**\n{role_definitions[role]}")

# --- 6. ä¸»èŠå¤©ç•Œé¢ ---

st.header(f"å½“å‰ä¼šè¯: {get_chat_title(st.session_state.messages)}")

# 6.1 æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "assistant":
            parse_and_render_message(message["content"])
        else:
            st.markdown(message["content"])

# RAG Prompt
template = f"""
ä½ ç°åœ¨çš„èº«ä»½æ˜¯ï¼š**{role}**ã€‚
è¯·æ ¹æ®ä»¥ä¸‹ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‘ï¼ˆå…³äºèˆé©¬è¡”æ¯é“¶å£¶çš„å²å®ï¼‰æ¥åˆ†æç”¨æˆ·çš„ã€åˆ›æ„æ–¹æ¡ˆã€‘ã€‚

**ä»»åŠ¡è¦æ±‚ï¼š**
1.  **çº åï¼š** å¦‚æœç”¨æˆ·çš„æè¿°ä¸å²å®å†²çªï¼Œè¯·åŠ¡å¿…æ¸©å’Œåœ°æŒ‡å‡ºå¹¶çº æ­£ã€‚
2.  **æ·±åŒ–ï¼š** åŸºäºä½ çš„è§’è‰²ï¼ˆ{role}ï¼‰ï¼Œä¸ºç”¨æˆ·çš„æ–¹æ¡ˆæä¾›ä¸“ä¸šçš„ä¼˜åŒ–å»ºè®®ã€‚

---
ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‘ï¼š
{{context}}
---
ã€ç”¨æˆ·çš„åˆ›æ„æ–¹æ¡ˆã€‘ï¼š
{{question}}
---
**ä½ çš„åˆ†æä¸å»ºè®®ï¼š**
"""
prompt = ChatPromptTemplate.from_template(template)


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
)

# 6.2 å¤„ç†æ–°æ¶ˆæ¯è¾“å…¥
if user_input := st.chat_input("è¯·è¾“å…¥ä½ çš„åˆ›æ„æ–¹æ¡ˆ..."):
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    save_chat_history(st.session_state.current_chat_id, st.session_state.messages)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        with st.spinner(f"{role} æ­£åœ¨æ€è€ƒä¸æŸ¥é˜…èµ„æ–™..."):
            try:
                for chunk in rag_chain.stream(user_input):
                    full_response += chunk
                    message_placeholder.markdown(full_response + "â–Œ")

                # æ¸²æŸ“æœ€ç»ˆç»“æœï¼ˆæŠ˜å æ€è€ƒè¿‡ç¨‹ï¼‰
                message_placeholder.empty()
                parse_and_render_message(full_response)

            except Exception as e:
                st.error(f"ç”Ÿæˆå‡ºé”™: {e}")
                full_response = "æŠ±æ­‰ï¼Œç³»ç»Ÿé‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"

    st.session_state.messages.append({"role": "assistant", "content": full_response})
    save_chat_history(st.session_state.current_chat_id, st.session_state.messages)

# æ ·å¼å¾®è°ƒ
st.markdown("""
<style>
    .stButton>button {border-radius: 8px;}
    /* è®©åˆ é™¤æŒ‰é’®å˜çº¢ä¸€ç‚¹ï¼Œæç¤ºå±é™©æ“ä½œï¼ˆå¯é€‰ï¼‰ */
    div[data-testid="column"]:nth-of-type(2) button {
        color: #ff4b4b;
        border-color: #ff4b4b;
    }
    /* è°ƒæ•´åŠ è½½æŒ‰é’®æ–‡æœ¬å·¦å¯¹é½ */
    div[data-testid="column"]:nth-of-type(1) button {
        text-align: left;
        border: 1px solid #eee;
    }
    .streamlit-expanderHeader {
        background-color: #f0f2f6;
        border-radius: 5px;
        font-size: 0.9em;
        color: #555;
    }
</style>
""", unsafe_allow_html=True)